# Awesome Machine Learning ğŸ¤–

[![github](https://img.shields.io/badge/GitHub-Repository-blue.svg)](https://github.com/ChenyuanLiu92/awesome-machine-learning)
[![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/ChenyuanLiu92/awesome-machine-learning/issues)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A curated list of cutting-edge machine learning papers, focusing on the latest research, open-source project, and trends in artificial intelligence.

## ğŸ“– Table of Contents

- [Latest Papers](#-latest-papers)
- [Blogs & News](#-news)
- [Open Source Projects](#-open-source-projects)
- [Research Trends](#-research-trends)
- [How to Contribute](#-how-to-contribute)

## ğŸ“š Latest Papers

### ğŸŒ Large Multi-Modal Models (LMMs)

#### Vision Language Models (VLA)
- **Ï€0: A Vision-Language-Action Flow Model for General Robot Control** - Physical Intelligence's VLA
  - [[Paper Link]](https://www.physicalintelligence.company/download/pi0.pdf) &#160;&#160;  [[Code]](https://github.com/Physical-Intelligence/openpi?tab=readme-ov-file)

- **RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation** - VLA for Bimanual Manipulation
  - [[Paper Link]](https://arxiv.org/abs/2410.07864) &#160;&#160; [[Code]](https://github.com/thu-ml/RoboticsDiffusionTransformer)

- **UniVLA: Learning to Act Anywhere with Task-centric Latent Actions**
  - [[Paper Link]](https://arxiv.org/abs/2505.06111) &#160;&#160; [[Code]](https://github.com/OpenDriveLab/UniVLA)

- **WorldVLA: Towards Autoregressive Action World Model** 
  - [[Paper Link]](https://arxiv.org/abs/2506.21539) &#160;&#160; [[Code]](https://github.com/alibaba-damo-academy/WorldVLA)

- **BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models** 
  - [[Paper Link]](https://arxiv.org/abs/2506.07961) &#160;&#160; [[Code]](https://github.com/BridgeVLA/BridgeVLA)



### ğŸ’¬ Large Language Models
- Coming soon...


### ğŸ‘€ Computer Vision

#### Object Detection

- **Detect Anything 3D in the Wild** 
  - [[Paper Link]](https://arxiv.org/abs/2504.07958) &#160;&#160; [[Code]](https://github.com/OpenDriveLab/DetAny3D)

  <!-- - [[Paper Link]]() &#160;&#160; [[Code]]() -->




### ğŸ” Natural Language Processing
- Coming soon...

### ğŸ§¬ AI for Science
- Coming soon...

### ğŸ“° Monthly Paper Highlights

#### July 2025
- Coming soon...

#### June 2024
- Coming soon...

#### May 2024
- Coming soon...

## ğŸ“° News

### News
- Coming soon...
<!-- - **Title** 
  - [Source Link](https://github.com/BridgeVLA/BridgeVLA)
  - Description -->

## ğŸš€ Open Source Projects

### Model & Algorithm Implementations
<!-- - **Transformers** - Hugging Face's pre-trained model library
- **Detectron2** - Facebook's object detection platform
- **OpenMMLab** - Multimedia laboratory's open-source algorithm library

### Tools & Platforms
- **Weights & Biases** - Experiment tracking and visualization
- **Neptune** - Machine learning experiment management
- **DVC** - Data version control -->

## ğŸ“ˆ Research Trends

### 2025 Hot Research Topics
<!-- 1. **Multimodal Foundation Models** - Unified models processing text, image, audio, and video
2. **Efficient Model Architectures** - Alternatives to Transformers (Mamba, RetNet)
3. **AI Alignment & Safety** - Constitutional AI, RLHF, and safety research
4. **Agentic AI Systems** - Autonomous agents capable of complex reasoning and action
5. **AI for Scientific Discovery** - Applications in biology, chemistry, and physics -->

### Emerging Research Areas
<!-- - **Mechanistic Interpretability** - Understanding how neural networks work internally
- **Scaling Laws** - Predicting model performance from compute and data
- **Few-Shot Learning** - Learning from minimal examples
- **Continual Learning** - Learning without forgetting previous knowledge
- **Federated Learning** - Training models across distributed data sources -->

## ğŸ“… Todo

- [ âœ… ] Advance in LLMs Area
- [ âœ… ] Advance in Computer Vision
- [ âœ… ] Advance in Generative AI

## ğŸ¤ How to Contribute

We welcome any form of contribution! Please follow these steps:

1. **Fork** this repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a **Pull Request**

### Contribution Guidelines
- Ensure links are valid and relevant
- Provide brief but informative descriptions
- Organize content according to existing format
- Prioritize quality over quantity

## ğŸ“ Contact

If you have any questions or suggestions, please reach out through:

- Create an [Issue](https://github.com/ChenyuanLiu92/awesome-machine-learning/issues)
- Send email to: liuchenyuan23@mails.ucas.edu.cn
- Discuss in [Discussions](https://github.com/ChenyuanLiu92/awesome-machine-learning/discussions)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## â­ Star History

If you find this project helpful, please give us a â­ï¸!

[![Star History Chart](https://api.star-history.com/svg?repos=ChenyuanLiu92e/awesome-machine-learning&type=Date)](https://star-history.com/#ChenyuanLiu92/awesome-machine-learning&Date)

---

**Last Updated**: July 02, 2025

**Maintainer**: [David Liu](https://github.com/ChenyuanLiu92)

*Continuously updated, contributions and follows are welcome!*
